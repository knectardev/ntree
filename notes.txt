At this point now planning on adding the following as discussed before, 

1.1 Rolling OLS (Local Linear Regression)
1.2 Autoregressive (AR / ARX) models
1.3 State-space linear trend models (Kalman)
1.4 Linear discriminant / logistic regression (classification, not regression)

The purpose of adding all these alternative derived metrics is to provide a reinforcement learning engine with a range of readily available options to do its experimentation with. As well as to learn more about this type of quantitative analysis in general. Obviously if I keep adding lines I will end up with spaghetti and I'm well aware of that. 

That plan makes sense, and the “spaghetti risk” is real — but you can avoid it if you treat these as features + diagnostics (for RL + analysis) rather than “more lines to stare at.”

Here’s a structure that will let you add all four families without the UI collapsing, and it will also make the RL setup cleaner.

1) Reframe: you’re building a feature factory, not an indicator zoo

Each item you listed can output two kinds of things:

Features (numbers for RL):

drift estimate, slope, z-scores, probabilities, confidence, residual stats…

Diagnostics (a small number of visual overlays):

ONE trend line (optional)

a few markers/heatmaps that show “regime” and “confidence”

Your RL agent should see lots of features.
Your eyeballs should see very few overlays.

2) What to implement from each model (minimal, high-value outputs)
1.1 Rolling OLS (Local linear regression)

Compute on returns (or price changes), not raw price.
Outputs:

mu_hat = expected next-bar return (or next-k-bar)

t_stat (or standardized mu_hat / se)

R2 (or adj R²)

sigma_hat (residual std)

optional: beta to 1–3 core factors (VWAP dev, slope, vol)

Overlay: none by default (or just a tiny “drift meter” / arrow)

1.2 AR / ARX

Keep it simple: AR(1–3) (or ARX with 1–2 exogenous terms).
Outputs:

phi_1..phi_p

mu_hat (1-step ahead return expectation)

innovation (residual / surprise)

stability (are roots inside unit circle?) OR just “model valid” flag

fit_quality (AIC/BIC or rolling loglik)

Overlay: none by default; maybe a “mean reversion vs momentum” badge.

1.3 State-space (Kalman local linear trend)

Outputs:

level

slope

slope_uncertainty (std)

level_uncertainty

normalized_slope = slope / slope_std ✅ extremely useful for gating

Overlay: one optional trend line (Kalman level), plus maybe slope confidence coloring.

1.4 Logistic / LDA classification

Define labels cleanly. Examples:

y = 1 if next 3 bars return > 0 (or exceeds threshold)

or y = 1 if breakout occurs within next k bars

or multiclass: {down / flat / up}

Outputs:

p_up (and p_down, p_flat)

calibration (Brier score rolling)

entropy (confidence)

decision_margin

Overlay: a thin probability ribbon at the bottom, or background shading (much better than lines).

3) Preventing spaghetti: use 3 display layers
Layer A — Price overlays (max 1–2 lines at a time)

Trend line (choose ONE: SMA / linear / Kalman)

Optional: one band (vol envelope or high/low band)

Layer B — Regime & confidence (heatmaps / shading)

Background shading for: trending / choppy / volatile / compressing

Small badges: “trend confidence high”, “AR stable”, “classifier confident”

Layer C — Panels (small multiples)

Instead of more lines, show small panels:

“Drift (mu)” line in its own panel

“Slope z-score” line

“Classifier p(up)” line

“Volatility / residual energy” line

This is how pros avoid spaghetti: separate axes.

4) RL integration: make features “plug-and-play”

Define a standard per-bar feature vector:

x_t = {
  price_features: ...
  trend_features: ...
  ols_features: ...
  ar_features: ...
  kalman_features: ...
  clf_features: ...
  quality_features: ...
}

Two things to include that many people forget (but RL needs)

Feature quality flags

is_warm (enough history?)

fit_ok (R² above min? AR stable? Kalman converged?)

confidence (entropy / z-score / t-stat)

Normalization

almost everything should be scaled by volatility or ATR-like measure

RL hates changing units/regimes

5) A pragmatic build order

If you want fastest learning per hour of work:

Kalman trend (level + slope + slope_z)

Rolling OLS on returns with mu_hat, t_stat, R²

Logistic for p_up + calibration metric

AR(1–3) last (easy to overfit, but useful once you have gating)

That order gives you clean regime + drift + probability before adding AR complexity.

6) One extra suggestion: add a “Feature Registry” and a “Viz Registry”

Feature registry: everything computed, named, normalized, quality-flagged

Viz registry: very small curated set of overlays/panels

Then your UI controls become:

“Pick trend overlay: SMA / linear / Kalman”

“Show panels: drift / p(up) / slope_z / vol”

“Developer mode: show raw lines” (optional)

If you want, paste (or point me to) the part of your JS where you assemble overlays/series for rendering, and I’ll suggest a clean “feature registry + panel” structure that lets you add all four model families without turning the chart into a hairball.