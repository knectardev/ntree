
you’re at the point where a real end-to-end test is worth running now.

You’ve got the three things that usually block “first real run”:

stable fixed schema (schema_v1) 

feature_registry

hard warmup + causal guarantees (unit tests + sentinel)

env semantics + cost model + baseline parity (so you can interpret results)

What I’d run as the first real test (fast, meaningful, low-risk):

Real test #1: “Can PPO beat z-fade on one week of SPY 1m RTH?”

Goal: not “holy grail,” just proof the loop learns something non-trivial and doesn’t churn itself to death.

A) Data slice

Instrument: SPY 1m

Session: RTH only (as you’ve defaulted)

Train: 5–10 trading days

Test: next 2–3 trading days (strictly later dates)

B) What to record

For both PPO and z-fade baseline:

net PnL after costs

turnover (position changes/day)

time-in-market

% exposure during breakout_flag=1

max drawdown (even crude)

If PPO can’t beat z-fade yet, that’s still a success if:

turnover drops over training

breakout exposure drops

the action distribution stops being random

C) How to run it (concretely)

Run your training script with:

short run, small timesteps, deterministic seed

debug series ON for a single evaluation episode (not all training)

Example pattern:

Train with return_reward_components=False (fast)

Evaluate with return_reward_components=True (diagnostic)

Confirm the export artifact + meta are produced, and confirm the schema matches:

schema_id == schema_v1

feature_names match registry order 

feature_registry

D) Expected outcomes (so you know if it “worked”)

A “successful first real test” looks like:

PPO learns a stable behavior (not constant flipping)

PPO’s average daily turnover is lower than random and ideally comparable to z-fade

PPO isn’t spending lots of time long/short while range_break_flag=1

PPO test PnL is at least “not catastrophically worse” than z-fade (profitability may come later)

If PPO is wildly negative with huge turnover:

reward shaping/cost too low

action coercion logic is being exploited

or features are too noisy / not normalized as expected